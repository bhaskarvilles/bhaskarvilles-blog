<!DOCTYPE html>
<html lang="en" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <!-- head.html --><!-- meta.html -->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Running LLaMA 3.1 Locally with Ollama: A Step-by-Step process | Bhaskar&#39;s Website</title>
<meta name="author" content="Bhaskar">
<meta name="description" content="A comprehensive guide to running Meta’s LLaMA 3.1 locally using Ollama, covering installation, setup, and fine-tuning." >
<meta name="keywords" content="AI,Machine Learning,LLaMA,Ollama">
<link rel="canonical" href="//localhost:1313/en/post/2024-08-20-running-llama3.1-locally-on-your-system/">



    
    <!-- twitterCard -->
    
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Running LLaMA 3.1 Locally with Ollama: A Step-by-Step process | Bhaskar&#39;s Website" />
    <meta name="twitter:description" content="A comprehensive guide to running Meta’s LLaMA 3.1 locally using Ollama, covering installation, setup, and fine-tuning." />
        <meta name="twitter:image" content="[/logo.png /featured-image.jpg /author-avatar.png]" />
        <meta name="twitter:site" content="@@bhaskarvilles" />
        <meta name="twitter:creator" content="@@bhaskarvilles" />
    
    <!-- openGraph -->
    <meta property="og:title" content="Running LLaMA 3.1 Locally with Ollama: A Step-by-Step process | Bhaskar&#39;s Website" />
    <meta property="og:description" content="A comprehensive guide to running Meta’s LLaMA 3.1 locally using Ollama, covering installation, setup, and fine-tuning." />
    <meta property="og:type" content="article" />
    <meta property="og:url" content="//localhost:1313/en/post/2024-08-20-running-llama3.1-locally-on-your-system/" />
        <meta property="og:image" content="[/logo.png /featured-image.jpg /author-avatar.png]" />
    <meta property="og:site_name" content="Bhaskar&#39;s Website" /><!-- js.html -->


    <script src="//localhost:1313/js/hugo-brewm.min.js" defer></script><!-- css.html -->



    <link rel="stylesheet" href="//localhost:1313/css/hugo-brewm.min.css">

    <!-- css/inline.html -->
    <style>
         
        body {max-width: 786px; margin: auto; padding: 2rem;}
        img {max-width: 86vw;}
    </style>
    
        
    <!-- css/verbatim.html -->
        <link href="//localhost:1313/css/typesetting/verbatim.min.css" rel="stylesheet" type="text/css">
    
</head>
<body >
    <!-- header.html -->
<header class="pagewidth">
    <div id="background-header" class="background" aria-hidden="true">
        <div class="grain" hidden></div>
    </div>
    
    <nav aria-label="Bypass">
        <a id="to-content" class="underline" href="#content" aria-label="Skip to Main Content">
            <span>Skip to Main Content</span>
            <kbd class="key" aria-hidden="true">c</kbd>
            <span class="screening" aria-hidden="true"></span>
        </a>
    </nav>
    
        <a id="logo" href="//localhost:1313/en/" aria-label="Bhaskar&#39;s Website" aria-description="Homepage">
                <!-- logotype.html --><svg id="logotype" xmlns="http://www.w3.org/2000/svg" version="1.1" width="476pt" aria-label="Bhaskar&#39;s Website">
            <text id="logotype__text" y="19.5pt" x="0">Bhaskar&#39;s Website</text>
        </svg>
        </a>
    
    <details class="presentation" id="top-nav">
        <summary class="on-deck">
            <span class="t t2">Navigation</span>
            <span class="menu-icon" role="presentation"></span>
        </summary>
        <nav tabindex="-1" aria-label="Top">
            <!-- menu.html -->
            <!-- search.html -->
<details id="has-search" class="presentation js-details" name="on-deck">
    <summary class="on-deck srm" accesskey="q" aria-keyshortcuts="q">
        <span class="t t2 srt">Search</span>
    </summary>
    
        <!-- pagefind.html -->
    <div id="search" class="on-hull">
        <div role="presentation" class="screening js-cgpn"></div>
    </div>
    <script src="//localhost:1313/pagefind/pagefind-ui.js" type="text/javascript"></script>
    <script>
        let pageFindInitialized = false;
        const initPageFind = function(event) {
            if (!pageFindInitialized) {
                new PagefindUI({
                    element: "#search",
                    showImages: false,
                    translations: {
                        placeholder: "Search"
                    }
                });
                pageFindInitialized = true;
                document.removeEventListener('DOMContentLoaded', initPageFind);
            }
        };
        document.addEventListener('DOMContentLoaded', initPageFind);
    </script>
        <noscript id="has-search-fallback" class="on-hull">
                
    <!-- duckduckgo.html -->
    <form id="duckduckgo" class="form on-plank"
        name="x" action="//duckduckgo.com/"
        role="search" aria-label="">
        <input type="hidden" value="localhost:1313" name="sites"></input>
        <input type="hidden" value="1" name="kh"></input>
        <input type="hidden" value="1" name="kn"></input>
        <input type="hidden" value="1" name="kac"></input>
        <input class="ldots form__input" type="search" placeholder="Search" name="q" role="searchbox"></input>
        <button class="form__button" type="submit" aria-label="Search">
            <img src="https://duckduckgo.com/assets/logo_header.v109.svg" alt="" role="presentation" aria-hidden="true">
        </button>
    </form>
    <div role="presentation" class="screening js-cgpn"></div>
        </noscript>
    
</details>
            <!-- menu.html -->
            <!-- i18n.html -->


        </nav>
        <div id="top-nav-screen" class="screening js-cpn" role="presentation" aria-hidden="true"></div>
    </details>
</header>
    
    <!-- [main] baseof.html -->
    <main id="page">
        <!-- main/header.html -->
        <header class="pagewidth">
            
                <!-- menu.html -->
    <menu class="srm">
        <a id="print-button" class="hide" href="javascript:window.print()" role="button" aria-label="Print">
            <span class="t srt" role="tooltip">Print</span>
        </a>
        <a id="navigatorShare" href="#share" role="button" aria-label="Share">
            <span class="t srt" role="tooltip">Share</span>
        </a>
        <a id="copyPermalink"  href="javascript:navigator.clipboard.writeText(window.location.href)" role="button" aria-label="Copy URL">
            <span id="copy" class="t srt" role="tooltip">Copy URL</span>
            <span id="isCopying" style="display: none;">Copying...</span>
            <span id="copyText" style="display: none;">Copy URL</span>
        </a>
    </menu>
    <button id="back" class="hide" type="button" onclick="history.back();" aria-label="Go Back">
        <span class="t srt" role="tooltip">Go Back</span>
    </button>
            
                <!-- nav.html -->
<details class="presentation" aria-expanded="true" id="has-breadcrumb" open>
    <summary id="breadcrumb" tabindex="-1">
        <span>Breadcrumb</span>
    </summary>
        <nav aria-labelledby="breadcrumb">
            <ul role="presentation" class="breadcrumb ">
                    <!-- breadcrumb.html -->
        <li>
            <a href="//localhost:1313/en/post/" aria-current="true">Post
            </a>
        </li>
    <li>
        <a href="" aria-current="page" tabindex="-1">Running LLaMA 3.1 Locally with Ollama: A Step-by-Step process
        </a>
    </li>
            </ul>
        </nav>
</details>
        </header>
        <div id="top" role="presentation">
            
        </div>
        
    <article id="main-article" class="pagewidth sf"
        role="document" aria-labelledby="title"
            data-pagefind-ignore="all">
        <header aria-labelledby="title">
            
            <!-- title.html -->
        <hgroup data-bionRead-safe>
            <h1 id="title"
                >Running LLaMA 3.1 Locally with Ollama: A Step-by-Step process</h1>
            <p  class="subtitle"
                role="doc-subtitle">A comprehensive guide to running Meta’s LLaMA 3.1 locally using Ollama, covering installation, setup, and fine-tuning.</p>
        </hgroup>
        </header>
        <!-- audio.html -->
        <section aria-labelledby="Title" id="content" data-bionRead-safe>
                <h3 id="running-llama-31-locally-with-ollama-a-step-by-step-process">Running LLaMA 3.1 Locally with Ollama: A Step-by-Step process</h3>
<p>With the rapid advancement in AI and machine learning, large language models (LLMs) have become an integral part of various applications, from chatbots to content generation. Meta’s LLaMA 3.1 (Large Language Model Meta AI) is one of the most powerful models available, and running it locally allows developers and researchers to explore its capabilities without relying on cloud-based services. One of the easiest ways to set up and run LLaMA 3.1 locally is using Ollama, a platform designed to streamline the deployment of LLMs.</p>
<p>In this blog post, we’ll walk you through the steps to get LLaMA 3.1 up and running on your local system using Ollama.</p>
<hr>
<h3 id="why-run-llama-31-locally"><strong>Why Run LLaMA 3.1 Locally?</strong></h3>
<p>Running LLaMA 3.1 locally comes with several benefits:</p>
<ul>
<li><strong>Privacy:</strong> No data is sent to external servers, ensuring that your data remains confidential.</li>
<li><strong>Customization:</strong> You have full control over the model, allowing you to tweak and fine-tune it to suit your specific needs.</li>
<li><strong>Performance:</strong> Depending on your hardware, local execution can be faster and more reliable than cloud-based alternatives.</li>
</ul>
<p><img src="https://about.fb.com/wp-content/uploads/2024/04/Meta-AI-Expasion_Header.gif" alt="Meta Llama3.1"></p>
<h3 id="prerequisites"><strong>Prerequisites</strong></h3>
<p>Before you start, make sure you have the following:</p>
<ul>
<li><strong>A capable machine:</strong> LLaMA 3.1 is a resource-intensive model, so you&rsquo;ll need a powerful machine, preferably with a GPU. At least 16GB of RAM and a high-end CPU are recommended. A dedicated GPU with a minimum of 8GB VRAM will significantly enhance performance.</li>
<li><strong>Python 3.8+ installed</strong> on your system.</li>
<li><strong>Docker:</strong> Ollama leverages Docker for containerized deployment, so ensure you have Docker installed and running on your system.</li>
<li><strong>NVIDIA Drivers and CUDA (for GPU acceleration):</strong> If you&rsquo;re running the model on a GPU, make sure you have the appropriate NVIDIA drivers and CUDA toolkit installed.</li>
</ul>
<h3 id="step-1-install-ollama"><strong>Step 1: Install Ollama</strong></h3>
<p>Ollama is designed to simplify the process of running LLMs like LLaMA locally. To get started, you&rsquo;ll need to install Ollama.</p>
<ol>
<li>
<p><strong>Install Docker:</strong></p>
<ul>
<li>On Ubuntu:
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">sudo apt-get update
</span></span><span class="line"><span class="cl">sudo apt-get install docker-ce docker-ce-cli containerd.io
</span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>On macOS:
<ul>
<li>Download and install Docker Desktop from <a href="https://www.docker.com/products/docker-desktop">here</a>.</li>
</ul>
</li>
<li>On Windows:
<ul>
<li>Download and install Docker Desktop from <a href="https://www.docker.com/products/docker-desktop">here</a>.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>Install Ollama:</strong>
Once Docker is installed, you can install Ollama by running:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">curl -sSL https://ollama.com/install.sh <span class="p">|</span> bash
</span></span></code></pre></td></tr></table>
</div>
</div><p>This script will download and set up Ollama on your system.</p>
</li>
</ol>
<h3 id="step-2-set-up-llama-31-with-ollama"><strong>Step 2: Set Up LLaMA 3.1 with Ollama</strong></h3>
<p>After installing Ollama, you can now set up LLaMA 3.1.</p>
<ol>
<li>
<p><strong>Pull the LLaMA 3.1 Docker Image:</strong>
Ollama provides pre-built Docker images for various models. To pull the LLaMA 3.1 image, run:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">ollama pull llama:3.1
</span></span></code></pre></td></tr></table>
</div>
</div><p>This command will download the LLaMA 3.1 model and its dependencies, which may take some time depending on your internet connection.</p>
</li>
<li>
<p><strong>Verify the Installation:</strong>
After the image is downloaded, you can verify that everything is set up correctly by running:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">ollama list
</span></span></code></pre></td></tr></table>
</div>
</div><p>This command should display LLaMA 3.1 as one of the available models.</p>
</li>
</ol>
<h3 id="step-3-running-llama-31-locally"><strong>Step 3: Running LLaMA 3.1 Locally</strong></h3>
<p>With everything set up, you can now run LLaMA 3.1 locally.</p>
<ol>
<li>
<p><strong>Start the LLaMA 3.1 Container:</strong>
To start the LLaMA 3.1 container, use the following command:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">ollama run llama:3.1
</span></span></code></pre></td></tr></table>
</div>
</div><p>This will launch the LLaMA 3.1 model inside a Docker container, ready to accept queries.</p>
</li>
<li>
<p><strong>Interacting with the Model:</strong>
You can interact with LLaMA 3.1 by sending input queries. For example:</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">ollama query llama:3.1 <span class="s2">&#34;What is the capital of France?&#34;</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>The model will process the query and return a response, such as &ldquo;Paris is the capital of France.&rdquo;</p>
</li>
</ol>
<p><img src="https://about.fb.com/wp-content/uploads/2024/04/04_Seamless-Search-1.gif" alt="Meta Ai Released by Meta.ai"></p>
<h3 id="step-4-fine-tuning-optional"><strong>Step 4: Fine-Tuning (Optional)</strong></h3>
<p>One of the advantages of running LLaMA 3.1 locally is the ability to fine-tune the model. Fine-tuning involves adjusting the model parameters based on your dataset, making the model more accurate for specific tasks.</p>
<p>To fine-tune LLaMA 3.1, you&rsquo;ll need a labeled dataset and a configuration file. The process involves several steps:</p>
<ol>
<li><strong>Prepare your dataset</strong> in a format compatible with Ollama.</li>
<li><strong>Create a configuration file</strong> specifying the training parameters.</li>
<li><strong>Run the fine-tuning command</strong>:
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-bash" data-lang="bash"><span class="line"><span class="cl">ollama train llama:3.1 --config your_config_file.yaml --data your_dataset
</span></span></code></pre></td></tr></table>
</div>
</div></li>
</ol>
<h3 id="conclusion"><strong>Conclusion</strong></h3>
<p>Running LLaMA 3.1 locally using Ollama is a powerful way to harness the capabilities of this advanced language model. Whether you&rsquo;re a researcher, developer, or enthusiast, this setup allows you to experiment with state-of-the-art AI without relying on cloud-based services.</p>
<p>By following the steps outlined in this guide, you can get LLaMA 3.1 up and running on your system in no time. From there, the possibilities are endless—from natural language processing tasks to AI-driven content creation. So, get started today and explore the world of large language models on your own terms!</p>

        </section>
    </article>
    <hr class="hide" style="margin: 1in 0;">
    <div id="contentinfo" class="pagewidth" role="contentinfo" data-pagefind-ignore="all">
            <!-- nav.html -->
<details class="presentation" aria-expanded="true" id="has-share" open>
    <summary id="share" tabindex="-1">
        <span>Share</span>
    </summary>
        <nav aria-labelledby="share">
            <ul role="presentation" class="share srm">
                    <!-- share.html -->
    <li id="has-mastodon">
        <!-- mastodon.html -->
    <form class="form" id="mastodon" action="//sharetomastodon.github.io/" target="_blank" rel="noopener noreferrer">
        <input id="mastodonTitle" type="hidden" name="title" value="Running LLaMA 3.1 Locally with Ollama: A Step-by-Step process">
        <input id="mastodonPermalink" type="hidden" name="url" value="//localhost:1313/en/post/2024-08-20-running-llama3.1-locally-on-your-system/">
        <input id="mastodonText" type="hidden" name="text" value="Running LLaMA 3.1 Locally with Ollama: A Step-by-Step process //localhost:1313/en/post/2024-08-20-running-llama3.1-locally-on-your-system/" disabled>
        <input id="mastodonInstance" type="url" class="ldots form__input" placeholder="Enter Mastodon instance (https://www.example.com)" aria-label="Mastodon instance URL">
        <button class="form__button" type="submit" aria-label="Share on Mastodon">
            <i class="icon mastodon sri" aria-hidden="true"></i>
            <span class="t srt" role="tooltip">Share on Mastodon</span>
        </button>
    </form>
    </li>
    <li>
        <a href="mailto:?subject=Running%20LLaMA%203.1%20Locally%20with%20Ollama%3a%20A%20Step-by-Step%20process&body=%2f%2flocalhost%3a1313%2fen%2fpost%2f2024-08-20-running-llama3.1-locally-on-your-system%2f" role="button" aria-label="Share on Email">
            <i class="email sri" aria-hidden="true"></i>
            <span class="t srt" role="tooltip">Share on Email</span>
        </a>
    </li>
    <li>
        <a href="whatsapp://send?text=Running%20LLaMA%203.1%20Locally%20with%20Ollama%3a%20A%20Step-by-Step%20process%20%2f%2flocalhost%3a1313%2fen%2fpost%2f2024-08-20-running-llama3.1-locally-on-your-system%2f" role="button" aria-label="Share on Whatsapp">
            <i class="whatsapp sri" aria-hidden="true"></i>
            <span class="t srt" role="tooltip">Share on Whatsapp</span>
        </a>
    </li>
    <li>
        <a rel="noopener noreferrer" target="_blank" href="https://telegram.me/share/url?text=Running%20LLaMA%203.1%20Locally%20with%20Ollama:%20A%20Step-by-Step%20process&amp;url=//localhost:1313/en/post/2024-08-20-running-llama3.1-locally-on-your-system/" role="button"
            aria-label="Share on Telegram in new tab">
            <i class="telegram sri" aria-hidden="true"></i>
            <span class="t srt" role="tooltip">Share on Telegram</span>
        </a>
    </li>
    <li>
        <a rel="noopener noreferrer" target="_blank" href="https://bsky.app/intent/compose?text=Running%20LLaMA%203.1%20Locally%20with%20Ollama:%20A%20Step-by-Step%20process&amp;url=//localhost:1313/en/post/2024-08-20-running-llama3.1-locally-on-your-system/" role="button"
            aria-label="Share on Bluesky in new tab">
            <i class="bluesky sri" aria-hidden="true"></i>
            <span class="t srt" role="tooltip">Share on Bluesky</span>
        </a>
    </li>
    <li>
        <a rel="noopener noreferrer" target="_blank" href="https://facebook.com/sharer/sharer.php?u=//localhost:1313/en/post/2024-08-20-running-llama3.1-locally-on-your-system/" role="button"
            aria-label="Share on Facebook in new tab">
            <i class="facebook sri" aria-hidden="true"></i>
            <span class="t srt" role="tooltip">Share on Facebook</span>
        </a>
    </li>
    <li>
        <a rel="noopener noreferrer" target="_blank" href="https://news.ycombinator.com/submitlink?u=//localhost:1313/en/post/2024-08-20-running-llama3.1-locally-on-your-system/&amp;t=Running%20LLaMA%203.1%20Locally%20with%20Ollama:%20A%20Step-by-Step%20process" role="button"
            aria-label="Share on Hackernews in new tab">
            <i class="hackernews sri" aria-hidden="true"></i>
            <span class="t srt" role="tooltip">Share on Hackernews</span>
        </a>
    </li>
    <li>
        <a rel="noopener noreferrer" target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=//localhost:1313/en/post/2024-08-20-running-llama3.1-locally-on-your-system/&amp;title=Running%20LLaMA%203.1%20Locally%20with%20Ollama:%20A%20Step-by-Step%20process&amp;summary=Running%20LLaMA%203.1%20Locally%20with%20Ollama:%20A%20Step-by-Step%20process&amp;source=//localhost:1313/en/post/2024-08-20-running-llama3.1-locally-on-your-system/" role="button"
            aria-label="Share on Linkedin in new tab">
            <i class="linkedin sri" aria-hidden="true"></i>
            <span class="t srt" role="tooltip">Share on Linkedin</span>
        </a>
    </li>
    <li>
        <a rel="noopener noreferrer" target="_blank" href="https://pinterest.com/pin/create/button/?url=//localhost:1313/en/post/2024-08-20-running-llama3.1-locally-on-your-system/&amp;media=//localhost:1313/en/post/2024-08-20-running-llama3.1-locally-on-your-system/&amp;description=Running%20LLaMA%203.1%20Locally%20with%20Ollama:%20A%20Step-by-Step%20process" role="button"
            aria-label="Share on Pinterest in new tab">
            <i class="pinterest sri" aria-hidden="true"></i>
            <span class="t srt" role="tooltip">Share on Pinterest</span>
        </a>
    </li>
    <li>
        <a rel="noopener noreferrer" target="_blank" href="https://reddit.com/submit/?url=//localhost:1313/en/post/2024-08-20-running-llama3.1-locally-on-your-system/&amp;resubmit=true&amp;title=Running%20LLaMA%203.1%20Locally%20with%20Ollama:%20A%20Step-by-Step%20process" role="button"
            aria-label="Share on Reddit in new tab">
            <i class="reddit sri" aria-hidden="true"></i>
            <span class="t srt" role="tooltip">Share on Reddit</span>
        </a>
    </li>
    <li>
        <a rel="noopener noreferrer" target="_blank" href="https://www.tumblr.com/widgets/share/tool?posttype=link&amp;title=Running%20LLaMA%203.1%20Locally%20with%20Ollama:%20A%20Step-by-Step%20process&amp;caption=Running%20LLaMA%203.1%20Locally%20with%20Ollama:%20A%20Step-by-Step%20process&amp;content=//localhost:1313/en/post/2024-08-20-running-llama3.1-locally-on-your-system/&amp;canonicalUrl=//localhost:1313/en/post/2024-08-20-running-llama3.1-locally-on-your-system/" role="button"
            aria-label="Share on Tumblr in new tab">
            <i class="tumblr sri" aria-hidden="true"></i>
            <span class="t srt" role="tooltip">Share on Tumblr</span>
        </a>
    </li>
    <li>
        <a rel="noopener noreferrer" target="_blank" href="http://vk.com/share.php?title=Running%20LLaMA%203.1%20Locally%20with%20Ollama:%20A%20Step-by-Step%20process&amp;url=//localhost:1313/en/post/2024-08-20-running-llama3.1-locally-on-your-system/" role="button"
            aria-label="Share on Vk in new tab">
            <i class="vk sri" aria-hidden="true"></i>
            <span class="t srt" role="tooltip">Share on Vk</span>
        </a>
    </li>
    <li>
        <a rel="noopener noreferrer" target="_blank" href="https://twitter.com/intent/tweet/?text=Running%20LLaMA%203.1%20Locally%20with%20Ollama:%20A%20Step-by-Step%20process&amp;url=//localhost:1313/en/post/2024-08-20-running-llama3.1-locally-on-your-system/" role="button"
            aria-label="Share on Twitter in new tab">
            <i class="twitter sri" aria-hidden="true"></i>
            <span class="t srt" role="tooltip">Share on Twitter</span>
        </a>
    </li>
    <li>
        <a rel="noopener noreferrer" target="_blank" href="https://www.xing.com/app/user?op=share;url=//localhost:1313/en/post/2024-08-20-running-llama3.1-locally-on-your-system/;title=Running%20LLaMA%203.1%20Locally%20with%20Ollama:%20A%20Step-by-Step%20process" role="button"
            aria-label="Share on Xing in new tab">
            <i class="xing sri" aria-hidden="true"></i>
            <span class="t srt" role="tooltip">Share on Xing</span>
        </a>
    </li>
            </ul>
        </nav>
</details>
    </div>
    
        
        <!-- main/footer.html -->
    <hr class="hide">
        <footer id="main-footer">
            <div class="column column--multicols pagewidth" style="--multicols: 2"><div id="main-footer-primary"
                        aria-labelledby="footer-1">
                        <p><strong class="section-title">Allam Bhaskara Ram <i class="icon copyleft"></i> 2025</strong><br>
Founder &amp; Tech Lead, <a href="https://kerdos.in" target="_blank">Kerdos Infrasoft Pvt. Ltd.</a><br>
Bangalore, India</p>
<br>
<strong class="section-title">Impressum</strong>
<p>Innovating India&rsquo;s digital infrastructure: AI, IoT, and Full Stack Solutions.<br>
Some rights reserved. For inquiries, contact: <a href="mailto:info@kerdos.in"><a href="mailto:info@kerdos.in">info@kerdos.in</a></a></p>

                    </div>
                <div id="main-footer-secondary"  class="column" style="--col: 15rem">
                        <div
                            aria-labelledby="footer-2">
                            <p><strong class="section-title">Allam Bhaskara Ram <i class="icon copyleft"></i> 2025</strong><br>
Pendiri &amp; Pemimpin Teknologi, <a href="https://kerdos.in" target="_blank">Kerdos Infrasoft Pvt. Ltd.</a><br>
Bangalore, India</p>
<br>
<strong class="section-title">Impresium</strong>
<p>Berinovasi dalam infrastruktur digital India: AI, IoT, dan Solusi Full Stack.<br>
Beberapa hak dilindungi undang-undang. Untuk pertanyaan, hubungi: <a href="mailto:info@kerdos.in"><a href="mailto:info@kerdos.in">info@kerdos.in</a></a></p>

                        </div>
                        <div id="coffee-counter">
                            <strong class="section-title">Coffee Stat</strong>
                            <p>Making this website has taken at least 13 cups of coffee, if not more.</p>
                        </div>                    
                    <!-- menu.html -->
                </div>
            </div>
        </footer>
    </main>
    <!-- footer.html -->
<footer id="body-footer" class="pagewidth" style="display: none;">
    <div id="background-footer" class="background hide" role="presentation" aria-hidden="true">
        <div class="grain" hidden></div>
    </div>
    <div id="focusMode"></div>
    <!-- a11y.html --><details id="has-a11y" class="presentation js-details hide" name="on-deck" aria-haspopup="true" aria-labelledby="has-a11y-summary">
    <summary id="has-a11y-summary" accesskey="a" aria-keyshortcuts="a">
        <span>&nbsp;Accessibility</span>
        <kbd class="key" aria-hidden="true">a</kbd>
    </summary>
    <!-- a11y console -->
    <fieldset id="a11y" role="region" aria-label="Accessibility"
        data-i18n-optimizeSR="Screen Reader Optimization"
        data-i18n-optimizeSRdesc="Optimize display and resources for screen reader users who navigate with a pointer device."
        data-i18n-colorSettings="Color Settings"
        data-i18n-darkMode="Dark Mode"
        data-i18n-light="Light"
        data-i18n-dark="Dark"
        data-i18n-contrast="Contrast"
        data-i18n-lessContrast="Low"
        data-i18n-moreContrast="High"
        data-i18n-defaultContrast="Default"
        data-i18n-colorPalette="Color Palette"
        data-i18n-defaultColor="Default"
        data-i18n-deuteranopia="Deuteranopia"
        data-i18n-protanopia="Protanopia"
        data-i18n-tritanopia="Tritanopia"
        data-i18n-monochrome="Monochrome"
        data-i18n-fontSize="Font Size"
        data-i18n-baselineStretch="Baseline Stretch"        
        data-i18n-OpenDyslexic="Use OpenDyslexic Font"
        data-i18n-menuControls="Accessibility Menu Controls"
        data-i18n-save="Save"
        data-i18n-reset="Reset"
        data-i18n-close="Close"
        data-i18n-bionRead="BionRead Mode"
        data-i18n-focusMode="Focus Mode"
        data-i18n-noLocalStorage="LocalStorage is not available in your browser. Settings won&#39;t be saved.">
    </fieldset>
    <div class="screening js-cpn" role="presentation" aria-hidden="true"></div>
</details>


    <div id="useBionRead" class="sri"></div>
    <!-- [top] bypass block -->
    <nav aria-label="Bypass">
        <a id="to-top" class="srm" href="#top" title="To Content Top" accesskey="c" aria-keyshortcuts="c" aria-label="To Content Top">
            <span class="t srt">To Content Top</span>
            <kbd class="key" aria-hidden="true">c</kbd>
        </a>
    </nav>
</footer>
    
    <!-- [post] single.html -->
    <div id="bionReadSnapshot" hidden></div>
    <!-- [background] baseof.html -->
    <div id="background-body"
        role="presentation" aria-hidden="true">
        <div class="grain" hidden></div>
        <div id="dwclock" hidden>
            <div id="min">
                <div class="hand"></div>
            </div>
            <div id="hour">
                <div class="hand"></div>
            </div>
        </div>
    </div>
</html>